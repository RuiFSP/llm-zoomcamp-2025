{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "877b7496",
   "metadata": {},
   "source": [
    "# Search Engine Example: From Basic to Advanced Techniques\n",
    "\n",
    "This notebook demonstrates the implementation of various search engine techniques, from simple to more advanced approaches. It shows how to build a text-based search system for a collection of documents from different courses.\n",
    "\n",
    "## Contents and Techniques Covered:\n",
    "\n",
    "1. **Data Loading and Exploration**\n",
    "   - Loading documents from a JSON source\n",
    "   - Organizing and exploring the document structure\n",
    "\n",
    "2. **Basic Text Vectorization**\n",
    "   - CountVectorizer: Simple word counting\n",
    "   - TF-IDF Vectorization: Term frequency-inverse document frequency\n",
    "   - Removing stop words to improve quality\n",
    "\n",
    "3. **Search Implementation**\n",
    "   - Computing similarity between queries and documents\n",
    "   - Using cosine similarity for comparing vector representations\n",
    "   - Filtering by course and boosting specific fields\n",
    "   - Creating a reusable `TextSearch` class\n",
    "\n",
    "4. **Dimensionality Reduction Techniques**\n",
    "   - TruncatedSVD (Latent Semantic Analysis)\n",
    "   - Non-negative Matrix Factorization (NMF)\n",
    "\n",
    "5. **Advanced Embedding with BERT**\n",
    "   - Using pre-trained BERT model for contextual embeddings\n",
    "   - Processing text through transformer architecture\n",
    "   - Batch processing for efficiency\n",
    "   - Saving embeddings for future use\n",
    "\n",
    "Each section builds on previous concepts, progressing from basic bag-of-words representations to advanced contextual embeddings using transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "66d44557-bc0d-43b1-8e4f-1a1973bd554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4516dc8",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration\n",
    "\n",
    "First, we load the document data from a JSON source and organize it into a structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "23dd3e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - Can I still join the course after the start date?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2] #example document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "152dc317-118b-46f3-bc2e-5dee4f66c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0faa21b7-adbf-44e4-bf02-d38998a12f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I still join the course after the...</td>\n",
       "      <td>Yes, even if you don't register, you're still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - I have registered for the Data Engine...</td>\n",
       "      <td>You don't need it. You're accepted. You can al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What can I do before the course starts?</td>\n",
       "      <td>You can start by installing and setting up all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      course                           section  \\\n",
       "0  data-engineering-zoomcamp  General course-related questions   \n",
       "1  data-engineering-zoomcamp  General course-related questions   \n",
       "2  data-engineering-zoomcamp  General course-related questions   \n",
       "3  data-engineering-zoomcamp  General course-related questions   \n",
       "4  data-engineering-zoomcamp  General course-related questions   \n",
       "\n",
       "                                            question  \\\n",
       "0               Course - When will the course start?   \n",
       "1  Course - What are the prerequisites for this c...   \n",
       "2  Course - Can I still join the course after the...   \n",
       "3  Course - I have registered for the Data Engine...   \n",
       "4   Course - What can I do before the course starts?   \n",
       "\n",
       "                                                text  \n",
       "0  The purpose of this document is to capture fre...  \n",
       "1  GitHub - DataTalksClub data-engineering-zoomca...  \n",
       "2  Yes, even if you don't register, you're still ...  \n",
       "3  You don't need it. You're accepted. You can al...  \n",
       "4  You can start by installing and setting up all...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(documents, columns=['course', 'section', 'question', 'text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50be37d",
   "metadata": {},
   "source": [
    "### Vector Space Model for Search\n",
    "\n",
    "In information retrieval, we represent documents as vectors in a mathematical space:\n",
    "\n",
    "- **Document Vectorization**: Converting text documents into numerical vectors\n",
    "- **Term-Document Matrix**:\n",
    "    - Rows: Documents in our collection\n",
    "    - Columns: Words/terms from our vocabulary\n",
    "    - Values: Importance or frequency of each term in each document\n",
    "  \n",
    "- **Bag-of-Words Approach**:\n",
    "  - Word order and grammar are disregarded\n",
    "  - Only the occurrence or frequency of words matters\n",
    "  - Uses sparse matrices (mostly zeros) for efficient storage\n",
    "  - Foundation for many information retrieval systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402618f3",
   "metadata": {},
   "source": [
    "### Understanding the Data Structure\n",
    "\n",
    "Let's examine the structure of our documents to understand what we're working with. Each document represents a Q&A entry from a course and contains fields like 'course', 'section', 'question', and 'text' (the answer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2f9ecbf7-13ce-4a4f-baaf-5ad989bdeb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I still join the course after the...</td>\n",
       "      <td>Yes, even if you don't register, you're still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - I have registered for the Data Engine...</td>\n",
       "      <td>You don't need it. You're accepted. You can al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What can I do before the course starts?</td>\n",
       "      <td>You can start by installing and setting up all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      course                           section  \\\n",
       "0  data-engineering-zoomcamp  General course-related questions   \n",
       "1  data-engineering-zoomcamp  General course-related questions   \n",
       "2  data-engineering-zoomcamp  General course-related questions   \n",
       "3  data-engineering-zoomcamp  General course-related questions   \n",
       "4  data-engineering-zoomcamp  General course-related questions   \n",
       "\n",
       "                                            question  \\\n",
       "0               Course - When will the course start?   \n",
       "1  Course - What are the prerequisites for this c...   \n",
       "2  Course - Can I still join the course after the...   \n",
       "3  Course - I have registered for the Data Engine...   \n",
       "4   Course - What can I do before the course starts?   \n",
       "\n",
       "                                                text  \n",
       "0  The purpose of this document is to capture fre...  \n",
       "1  GitHub - DataTalksClub data-engineering-zoomca...  \n",
       "2  Yes, even if you don't register, you're still ...  \n",
       "3  You don't need it. You're accepted. You can al...  \n",
       "4  You can start by installing and setting up all...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.course == 'data-engineering-zoomcamp'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7acf52c",
   "metadata": {},
   "source": [
    "## 2. Basic Text Vectorization\n",
    "\n",
    "Here we explore various text vectorization techniques, starting with a simple example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c6f62369-fc0d-484f-abc4-ba846a3a4bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5893ad",
   "metadata": {},
   "source": [
    "### Basic Text Representation: CountVectorizer\n",
    "\n",
    "We'll start with the most basic approach: representing documents by counting word occurrences.\n",
    "\n",
    "`CountVectorizer` from scikit-learn:\n",
    "- Converts a collection of text documents into a matrix of token counts\n",
    "- Creates a \"vocabulary\" of all unique words in the corpus\n",
    "- Represents each document as a vector of word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b51522f4-2e65-42ef-8ccc-310adb032658",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "94f4da02-d93a-412f-8a99-3b5d6c23056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the purpose of this example, we will use a small set of documents\n",
    "# in a real-world scenario, you would use a larger set of documents\n",
    "\n",
    "docs_example = [\n",
    "    \"January course details, register now\",\n",
    "    \"Course prerequisites listed in January catalog\",\n",
    "    \"Submit January course homework by end of month\",\n",
    "    \"Register for January course, no prerequisites\",\n",
    "    \"January course setup: Python and Google Cloud\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d2c5bdbc-aaaa-4da6-b19d-5f9d4fdb7eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">input&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;content&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('encoding',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">encoding&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;utf-8&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decode_error',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decode_error&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;strict&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strip_accents',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">strip_accents&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lowercase',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">lowercase&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('preprocessor',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">preprocessor&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tokenizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tokenizer&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stop_words',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">stop_words&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('token_pattern',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">token_pattern&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;(?u)\\\\b\\\\w\\\\w+\\\\b&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ngram_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ngram_range&nbsp;</td>\n",
       "            <td class=\"value\">(1, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('analyzer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">analyzer&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;word&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_df&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_df&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('vocabulary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">vocabulary&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('binary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">binary&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dtype&nbsp;</td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.int64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(docs_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8041bcfe-0b1b-4c06-ba64-917440f89f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'by', 'catalog', 'cloud', 'course', 'details', 'end', 'for',\n",
       "       'google', 'homework', 'in', 'january', 'listed', 'month', 'no',\n",
       "       'now', 'of', 'prerequisites', 'python', 'register', 'setup',\n",
       "       'submit'], dtype=object)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = cv.get_feature_names_out()\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f151c0e0-bfa1-4ea4-9cbd-e3544ebfcb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.transform(docs_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "061bca2a-4af8-4ccf-82a5-310952a1cab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "11af73f9-96e1-4e3b-b9a1-34fd9c60dc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catalog</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>details</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homework</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>january</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listed</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>now</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prerequisites</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>register</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setup</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submit</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  1  2  3  4\n",
       "and            0  0  0  0  1\n",
       "by             0  0  1  0  0\n",
       "catalog        0  1  0  0  0\n",
       "cloud          0  0  0  0  1\n",
       "course         1  1  1  1  1\n",
       "details        1  0  0  0  0\n",
       "end            0  0  1  0  0\n",
       "for            0  0  0  1  0\n",
       "google         0  0  0  0  1\n",
       "homework       0  0  1  0  0\n",
       "in             0  1  0  0  0\n",
       "january        1  1  1  1  1\n",
       "listed         0  1  0  0  0\n",
       "month          0  0  1  0  0\n",
       "no             0  0  0  1  0\n",
       "now            1  0  0  0  0\n",
       "of             0  0  1  0  0\n",
       "prerequisites  0  1  0  1  0\n",
       "python         0  0  0  0  1\n",
       "register       1  0  0  1  0\n",
       "setup          0  0  0  0  1\n",
       "submit         0  0  1  0  0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_docs = pd.DataFrame(X.toarray(), columns=names).T\n",
    "df_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a9630a4d-797d-45d8-9849-2c4b3c02c249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>catalog</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>details</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homework</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>january</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listed</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prerequisites</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>register</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setup</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submit</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  1  2  3  4\n",
       "catalog        0  1  0  0  0\n",
       "cloud          0  0  0  0  1\n",
       "course         1  1  1  1  1\n",
       "details        1  0  0  0  0\n",
       "end            0  0  1  0  0\n",
       "google         0  0  0  0  1\n",
       "homework       0  0  1  0  0\n",
       "january        1  1  1  1  1\n",
       "listed         0  1  0  0  0\n",
       "month          0  0  1  0  0\n",
       "prerequisites  0  1  0  1  0\n",
       "python         0  0  0  0  1\n",
       "register       1  0  0  1  0\n",
       "setup          0  0  0  0  1\n",
       "submit         0  0  1  0  0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english') # removing common English stop words\n",
    "X = cv.fit_transform(docs_example)\n",
    "\n",
    "names = cv.get_feature_names_out()\n",
    "\n",
    "df_docs = pd.DataFrame(X.toarray(), columns=names).T\n",
    "df_docs\n",
    "\n",
    "# this is a bag of words representation\n",
    "# each row is a word, each column is a document\n",
    "# the values are the counts of the words in the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "11b9f3d6-5d93-4a29-baf6-4cf8c5cf1d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38f1502",
   "metadata": {},
   "source": [
    "### Improved Text Representation: TF-IDF Vectorization\n",
    "\n",
    "**TF-IDF (Term Frequency-Inverse Document Frequency)** improves on simple word counting:\n",
    "\n",
    "- **Term Frequency (TF)**: How often a word appears in a document\n",
    "  - More frequent words in a document are more important (higher weight)\n",
    "\n",
    "- **Inverse Document Frequency (IDF)**: How unique a word is across documents\n",
    "  - Words that appear in many documents get lower weights\n",
    "  - Rare, distinctive words get higher weights\n",
    "\n",
    "This approach gives higher weight to terms that are:\n",
    "1. Important within a specific document (high TF)\n",
    "2. Distinctive across the document collection (high IDF)\n",
    "\n",
    "TF-IDF helps reduce the importance of common words that appear in many documents but aren't very meaningful (like \"the\", \"is\", \"of\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "23a63806-bbb3-4238-ad78-11aed2c1c9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>catalog</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>details</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homework</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>january</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listed</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prerequisites</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>register</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setup</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submit</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0     1     2     3     4\n",
       "catalog        0.00  0.57  0.00  0.00  0.00\n",
       "cloud          0.00  0.00  0.00  0.00  0.47\n",
       "course         0.33  0.27  0.23  0.36  0.23\n",
       "details        0.69  0.00  0.00  0.00  0.00\n",
       "end            0.00  0.00  0.47  0.00  0.00\n",
       "google         0.00  0.00  0.00  0.00  0.47\n",
       "homework       0.00  0.00  0.47  0.00  0.00\n",
       "january        0.33  0.27  0.23  0.36  0.23\n",
       "listed         0.00  0.57  0.00  0.00  0.00\n",
       "month          0.00  0.00  0.47  0.00  0.00\n",
       "prerequisites  0.00  0.46  0.00  0.61  0.00\n",
       "python         0.00  0.00  0.00  0.00  0.47\n",
       "register       0.56  0.00  0.00  0.61  0.00\n",
       "setup          0.00  0.00  0.00  0.00  0.47\n",
       "submit         0.00  0.00  0.47  0.00  0.00"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = TfidfVectorizer(stop_words='english')\n",
    "X = cv.fit_transform(docs_example)\n",
    "\n",
    "names = cv.get_feature_names_out()\n",
    "\n",
    "df_docs = pd.DataFrame(X.toarray(), columns=names).T\n",
    "df_docs.round(2)\n",
    "\n",
    "# this is a TF-IDF representation\n",
    "# each row is a word, each column is a document\n",
    "# the values are the TF-IDF scores of the words in the documents\n",
    "\n",
    "\n",
    "# TF-IDF stands for Term Frequency-Inverse Document Frequency\n",
    "# it is a statistical measure that evaluates the importance of a word in a document relative to a\n",
    "# collection of documents (corpus)\n",
    "# the higher the score, the more important the word is in that document,\n",
    "# the lower the score, the less important the word is in that document\n",
    "# the more rare the word is in that document, the higher the score,\n",
    "# and the more common the word is in that document, the lower the score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fefdd70",
   "metadata": {},
   "source": [
    "## 3. Search Implementation\n",
    "\n",
    "Now we implement search functionality using the vectorized representations and similarity measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7c39d3be-281d-4d01-a645-e5a49678f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Do I need to know python to sign up for the January course?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2a0f5f35-b1b4-4e8a-b0af-7b83e8830b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.39515588, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.39515588, 0.        , 0.        ,\n",
       "        0.        , 0.829279  , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = cv.transform([query])\n",
    "q.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9bb650c2-5ec3-4419-a27c-8db1af022206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'catalog': np.float64(0.0),\n",
       " 'cloud': np.float64(0.0),\n",
       " 'course': np.float64(0.39515588491314224),\n",
       " 'details': np.float64(0.0),\n",
       " 'end': np.float64(0.0),\n",
       " 'google': np.float64(0.0),\n",
       " 'homework': np.float64(0.0),\n",
       " 'january': np.float64(0.39515588491314224),\n",
       " 'listed': np.float64(0.0),\n",
       " 'month': np.float64(0.0),\n",
       " 'prerequisites': np.float64(0.0),\n",
       " 'python': np.float64(0.8292789960182417),\n",
       " 'register': np.float64(0.0),\n",
       " 'setup': np.float64(0.0),\n",
       " 'submit': np.float64(0.0)}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dict = dict(zip(names, q.toarray()[0]))\n",
    "query_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b099d689-1156-4f49-8cfa-4bdda6c60734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'catalog': np.float64(0.5675015398728066),\n",
       " 'cloud': np.float64(0.0),\n",
       " 'course': np.float64(0.2704175244456293),\n",
       " 'details': np.float64(0.0),\n",
       " 'end': np.float64(0.0),\n",
       " 'google': np.float64(0.0),\n",
       " 'homework': np.float64(0.0),\n",
       " 'january': np.float64(0.2704175244456293),\n",
       " 'listed': np.float64(0.5675015398728066),\n",
       " 'month': np.float64(0.0),\n",
       " 'prerequisites': np.float64(0.45785666908911726),\n",
       " 'python': np.float64(0.0),\n",
       " 'register': np.float64(0.0),\n",
       " 'setup': np.float64(0.0),\n",
       " 'submit': np.float64(0.0)}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict = dict(zip(names, X.toarray()[1]))\n",
    "doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8b4600a5-1924-4680-acc9-55b1f34a4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qd = pd.DataFrame([query_dict, doc_dict], index=['query', 'doc']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8afb041c-da6f-4f20-b58e-12bc1800c223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.21371415233666782)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the cosine similarity between the query and the document manually -  this is the dot product of the two vectors\n",
    "(df_qd['query'] * df_qd['doc']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dbe38cf2-5925-48c1-be6b-4867e63b1731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25955955],\n",
       "       [0.21371415],\n",
       "       [0.17843726],\n",
       "       [0.28419115],\n",
       "       [0.57137158]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dot(q.T).toarray() # this is the same as the above, but using the dot product of the two vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4949c0e1",
   "metadata": {},
   "source": [
    "### Query-Document Similarity with Cosine Similarity\n",
    "\n",
    "To find relevant documents for a query, we need to measure how similar they are:\n",
    "\n",
    "- **Cosine Similarity**: Measures the cosine of the angle between two vectors\n",
    "  - Value ranges from -1 (opposite) to 1 (identical)\n",
    "  - For text vectors with non-negative values, range is 0 to 1\n",
    "  - Higher value = more similar documents\n",
    "  - Not affected by document length (unlike dot product)\n",
    "  \n",
    "- **Formula**: $\\text{cosine}(A,B) = \\frac{A \\cdot B}{||A|| \\times ||B||}$\n",
    "  - Where $A \\cdot B$ is the dot product\n",
    "  - And $||A||$ is the magnitude of vector A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "66c49ec8-1ddb-4c77-bbd9-87afd6aaeac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "79d49a2a-1e7e-432d-b5fe-cb7d83a7eef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25955955],\n",
       "       [0.21371415],\n",
       "       [0.17843726],\n",
       "       [0.28419115],\n",
       "       [0.57137158]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this the cosine similarity between the query and the document, it's the same as the dot product of the two vectors\n",
    "cosine_similarity(X, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2e77c501b449eb96",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['course', 'section', 'question', 'text'], dtype='object')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4a1a0cbe2543cd99",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields = ['section', 'question', 'text']\n",
    "transformers = {}\n",
    "matrices = {}\n",
    "\n",
    "for field in fields:\n",
    "    cv = TfidfVectorizer(stop_words='english', min_df=3)\n",
    "    X = cv.fit_transform(df[field])\n",
    "\n",
    "    transformers[field] = cv\n",
    "    matrices[field] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e2f74df93ee2e49c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['001', '01', '02', ..., 'zones', 'zoom', 'zoomcamp'],\n",
       "      shape=(2118,), dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers['text'].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c03aea39445ae9e8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 26463 stored elements and shape (948, 2118)>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrices['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "767dd06e91817dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I just singned up. Is it too late to join the course?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7e48c3a96d93e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = transformers['text'].transform([query])\n",
    "score = cosine_similarity(matrices['text'], q).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f35c13cc-ae93-4b64-b6f2-8519f1b1175e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3336047 , 0.        , 0.        , 0.1328874 , 0.        ,\n",
       "       0.        , 0.        , 0.12722114, 0.        , 0.        ])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df.course == 'data-engineering-zoomcamp').values\n",
    "score = score * mask\n",
    "score[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7af8de09-054e-4638-af4d-27eb9335187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fd76b3b5-092c-4c4d-b06b-c1a2ea73e032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  15,  22,  27,  38, 287,   3,   7, 113,  11])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argsort(-score)[:10]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "92c5e093-18a5-4e07-b1ba-825ae8281144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3336047 , 0.23530268, 0.22668   , 0.1894954 , 0.16484429,\n",
       "       0.13921764, 0.1328874 , 0.12722114, 0.1207499 , 0.10830554])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e1629617-e109-4aeb-a758-42b621665bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      The purpose of this document is to capture fre...\n",
       "15     No, late submissions are not allowed. But if t...\n",
       "22     It's up to you which platform and environment ...\n",
       "27     You can do most of the course without a cloud....\n",
       "38     You will have two attempts for a project. If t...\n",
       "287    This error could result if you are using some ...\n",
       "3      You don't need it. You're accepted. You can al...\n",
       "7      Yes, we will keep all the materials after the ...\n",
       "113    In the join queries, if we mention the column ...\n",
       "11     No, you can only get a certificate if you fini...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[idx].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "070e9bfc-7364-4746-8a13-5429c1e3793f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['section', 'question', 'text']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "39a0f583-7c95-493d-b54e-19737c4e6807",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I just signed up. Is it too late to join the course?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999ddb87",
   "metadata": {},
   "source": [
    "### Enhancing Relevance: Field Boosting and Filtering\n",
    "\n",
    "To improve search results, we can:\n",
    "\n",
    "1. **Field Boosting**: Give different weights to different fields\n",
    "   - For example, we might consider matching text in a \"question\" field more important than in a \"description\" field\n",
    "   - This is done by multiplying similarity scores by a boost factor\n",
    "\n",
    "2. **Filtering**: Restrict results by specific criteria\n",
    "   - We can filter results by metadata like course name, date, etc.\n",
    "   - Implemented by masking scores (setting non-matching documents to zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ecde3950-b575-4837-974f-7353431e3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define boost factors: we're giving the 'question' field 3x importance\n",
    "boost = {'question': 3.0}  # Other fields will get default weight of 1.0\n",
    "\n",
    "# Initialize score array with zeros for each document\n",
    "score = np.zeros(len(df))\n",
    "\n",
    "# For each field (section, question, text), calculate similarity and apply boost\n",
    "for f in fields:\n",
    "    # Get boost value (default 1.0 if not specified)\n",
    "    b = boost.get(f, 1.0)\n",
    "    \n",
    "    # Transform query into TF-IDF space for this field\n",
    "    q = transformers[f].transform([query])\n",
    "    \n",
    "    # Calculate cosine similarity between query and all documents for this field\n",
    "    s = cosine_similarity(matrices[f], q).flatten()\n",
    "    \n",
    "    # Add the boosted similarity score to the total score\n",
    "    score = score + b * s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "76926c4a-60c0-4547-a3e9-3ed5c01cc9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filters to narrow down results by metadata\n",
    "filters = {\n",
    "    'course': 'data-engineering-zoomcamp'  # Only show results from this course\n",
    "}\n",
    "\n",
    "# Apply each filter by masking out non-matching documents\n",
    "for field, value in filters.items():\n",
    "    # Create a boolean mask: True for matching documents, False for non-matching\n",
    "    mask = (df[field] == value).values\n",
    "    \n",
    "    # Multiply scores by mask - this sets scores to 0 for non-matching documents\n",
    "    # Since any number * 0 = 0, non-matching documents will get a final score of 0\n",
    "    score = score * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "53da7a34-8052-48a1-9041-bb0f94416448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What are the prerequisites for this course?',\n",
       "  'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How can we contribute to the course?',\n",
       "  'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Which playlist on YouTube should I refer to?',\n",
       "  'text': 'All the main videos are stored in the Main “DATA ENGINEERING” playlist (no year specified). The Github repository has also been updated to show each video with a thumbnail, that would bring you directly to the same playlist below.\\nBelow is the MAIN PLAYLIST’. And then you refer to the year specific playlist for additional videos for that year like for office hours videos etc. Also find this playlist pinned to the slack channel.\\nh\\nttps://youtube.com/playlist?list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&si=NspQhtZhZQs1B9F-'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - how many Zoomcamps in a year?',\n",
       "  'text': \"There are 3 Zoom Camps in a year, as of 2024. However, they are for separate courses:\\nData-Engineering (Jan - Apr)\\nMLOps (May - Aug)\\nMachine Learning (Sep - Jan)\\nThere's only one Data-Engineering Zoomcamp “live” cohort per year, for the certification. Same as for the other Zoomcamps.\\nThey follow pretty much the same schedule for each cohort per zoomcamp. For Data-Engineering it is (generally) from Jan-Apr of the year. If you’re not interested in the Certificate, you can take any zoom camps at any time, at your own pace, out of sync with any “live” cohort.\"},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\"},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\"},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I get support if I take the course in the self-paced mode?',\n",
       "  'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - \\u200b\\u200bHow many hours per week am I expected to spend on this  course?',\n",
       "  'text': 'It depends on your background and previous experience with modules. It is expected to require about 5 - 15 hours per week. [source1] [source2]\\nYou can also calculate it yourself using this data and then update this answer.'}]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argsort(-score)[:10]\n",
    "results = df.iloc[idx]\n",
    "results.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "74ab72b1-47fd-451b-9660-e4df629c4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSearch:\n",
    "    \"\"\"A versatile search engine for text documents that supports:\n",
    "    - Multiple text fields\n",
    "    - Field boosting\n",
    "    - Filtering by metadata\n",
    "    - TF-IDF vectorization\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text_fields):\n",
    "        \"\"\"Initialize the search engine with specified text fields to index.\n",
    "        \n",
    "        Args:\n",
    "            text_fields (list): List of field names to use for searching\n",
    "        \"\"\"\n",
    "        self.text_fields = text_fields\n",
    "        self.matrices = {}       # Will store TF-IDF matrices for each field\n",
    "        self.vectorizers = {}    # Will store vectorizers for each field\n",
    "\n",
    "    def fit(self, records, vectorizer_params={}):\n",
    "        \"\"\"Process and index the document collection.\n",
    "        \n",
    "        Args:\n",
    "            records (list): List of document dictionaries\n",
    "            vectorizer_params (dict): Optional parameters for the TF-IDF vectorizer\n",
    "        \"\"\"\n",
    "        # Convert records to a DataFrame if they aren't already\n",
    "        self.df = pd.DataFrame(records)\n",
    "\n",
    "        # For each text field, create a vectorizer and transform the text\n",
    "        for f in self.text_fields:\n",
    "            # Initialize a TF-IDF vectorizer with optional parameters\n",
    "            cv = TfidfVectorizer(**vectorizer_params)\n",
    "            \n",
    "            # Transform the text in this field to TF-IDF vectors\n",
    "            X = cv.fit_transform(self.df[f])\n",
    "            \n",
    "            # Store both the matrix and vectorizer for later use\n",
    "            self.matrices[f] = X\n",
    "            self.vectorizers[f] = cv\n",
    "\n",
    "    def search(self, query, n_results=10, boost={}, filters={}):\n",
    "        \"\"\"Search for documents matching the query.\n",
    "        \n",
    "        Args:\n",
    "            query (str): The search query\n",
    "            n_results (int): Maximum number of results to return\n",
    "            boost (dict): Field boost factors (e.g., {'title': 3.0})\n",
    "            filters (dict): Metadata filters (e.g., {'category': 'science'})\n",
    "            \n",
    "        Returns:\n",
    "            list: Matching documents as dictionaries\n",
    "        \"\"\"\n",
    "        # Initialize scores array\n",
    "        score = np.zeros(len(self.df))\n",
    "\n",
    "        # Calculate similarity for each field and apply boosts\n",
    "        for f in self.text_fields:\n",
    "            # Get boost factor (default 1.0)\n",
    "            b = boost.get(f, 1.0)\n",
    "            \n",
    "            # Transform query using this field's vectorizer\n",
    "            q = self.vectorizers[f].transform([query])\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            s = cosine_similarity(self.matrices[f], q).flatten()\n",
    "            \n",
    "            # Add weighted similarity to total score\n",
    "            score = score + b * s\n",
    "\n",
    "        # Apply any filters to restrict results\n",
    "        for field, value in filters.items():\n",
    "            mask = (self.df[field] == value).values\n",
    "            score = score * mask\n",
    "\n",
    "        # Get indices of top scoring documents\n",
    "        idx = np.argsort(-score)[:n_results]\n",
    "        \n",
    "        # Return the top results as dictionaries\n",
    "        results = self.df.iloc[idx]\n",
    "        return results.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954a795",
   "metadata": {},
   "source": [
    "### Creating a Reusable TextSearch Class\n",
    "\n",
    "We encapsulate all our search functionality into a reusable class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8fe5e13d-02aa-4f77-862e-70f5b14c8067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['section', 'question', 'text']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "db06ee90-31d1-4842-829a-662a812eed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = TextSearch(text_fields=['section', 'question', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7c3ec354-9382-4fee-94f4-458a5044f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a908b98c",
   "metadata": {},
   "source": [
    "### Using Our TextSearch Class\n",
    "\n",
    "Now we'll use our TextSearch class to build a complete search solution. This encapsulates all the concepts we've learned:\n",
    "\n",
    "1. We initialize the search index with the fields we want to search\n",
    "2. We fit/train the index on our document collection\n",
    "3. We execute a search with boosting and filtering\n",
    "\n",
    "This approach provides a clean, reusable interface for search functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ecde6ac7-ce80-4b07-b079-55e822f399f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I just signed up. Is it too late to join the course?'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "09895ca8-6a96-4e34-90fe-de6a1b117681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Homework - Are late submissions of homework allowed?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(\n",
    "    query='I just signed up. Is it too late to join the course?',\n",
    "    n_results=5,\n",
    "    boost={'question': 3.0},\n",
    "    filters={'course': 'data-engineering-zoomcamp'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa588dac",
   "metadata": {},
   "source": [
    "## 4. Dimensionality Reduction Techniques\n",
    "\n",
    "As our vocabulary grows, our vectors become very high-dimensional (one dimension per unique word), leading to:\n",
    "- Increased computational complexity\n",
    "- The \"curse of dimensionality\" (sparse, distant vectors)\n",
    "- Difficulty capturing semantic relationships between words\n",
    "\n",
    "Dimensionality reduction addresses these issues by:\n",
    "- Projecting high-dimensional vectors into a lower-dimensional space\n",
    "- Preserving semantic relationships between documents\n",
    "- Potentially capturing latent topics or themes\n",
    "- Improving efficiency and sometimes accuracy of similarity calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cf7a1601-cdae-4299-b3ad-5fa73964b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = matrices['text']\n",
    "cv = transformers['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "22c13291-b493-480e-9e10-256eedb9c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=16)\n",
    "X_emb = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583b44e",
   "metadata": {},
   "source": [
    "### Truncated SVD (Latent Semantic Analysis)\n",
    "\n",
    "**Singular Value Decomposition (SVD)** is a matrix factorization technique that decomposes our document-term matrix into three matrices:\n",
    "\n",
    "- **Truncated SVD** keeps only the top K components (16 in our example)\n",
    "- Also known as **Latent Semantic Analysis (LSA)** when applied to text data\n",
    "- **Benefits**:\n",
    "  - Captures latent semantic relationships between words\n",
    "  - Words with similar meanings tend to be closer in the reduced space\n",
    "  - Can discover synonyms and related concepts\n",
    "  - Addresses the \"synonym problem\" in information retrieval\n",
    "  - Significantly reduces dimensionality (from thousands to dozens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "69b68353-1296-43e4-8501-955010f0fc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08800366, -0.07517865, -0.10105712,  0.05230767,  0.05235927,\n",
       "       -0.05944197,  0.02153147,  0.05269332, -0.20656883,  0.31692401,\n",
       "        0.0293634 ,  0.10904857, -0.11577076,  0.03276341,  0.00761791,\n",
       "       -0.00146267])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2600579f-a557-4dde-bc3e-b24afc526ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'I just signed up. Is it too late to join the course?'\n",
    "\n",
    "Q = cv.transform([query])\n",
    "Q_emb = svd.transform(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bd4b9419-b36b-45a8-9152-caa31a4761d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04353771, -0.03066805, -0.04424086,  0.01347335,  0.02497004,\n",
       "       -0.0518951 ,  0.01203983,  0.03418793, -0.12052568,  0.1735309 ,\n",
       "        0.02738705,  0.0752527 , -0.06151985,  0.02799265,  0.01159803,\n",
       "       -0.02185774])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "103badbb-881b-46ff-b4ab-302265e190cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.11482853349220448)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X_emb[0], Q_emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c015d99a-396f-4de6-bd8d-719b30eebbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cosine_similarity(X_emb, Q_emb).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "53728975-091a-4f59-9ba8-8b3cb97e8c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(-score)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "af6d4f7c-cef3-4c15-8c79-d2041afbf6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       " \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'No, it’s not possible. The form is closed after the due date. But don’t worry, homework is not mandatory for finishing the course.',\n",
       " 'If you have submitted two projects (and peer-reviewed at least 3 course-mates’ projects for each submission), you will get the certificate for the course. According to the course coordinator, Alexey Grigorev, only two projects are needed to get the course certificate.\\n(optional) David Odimegwu',\n",
       " 'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]',\n",
       " \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       " 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       " 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       " \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'Please choose the closest one to your answer. Also do not post your answer in the course slack channel.']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.loc[idx].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa3eda",
   "metadata": {},
   "source": [
    "### Non-negative Matrix Factorization (NMF)\n",
    "\n",
    "**Non-negative Matrix Factorization (NMF)** is an alternative dimensionality reduction technique with unique properties:\n",
    "\n",
    "- **Key Characteristics**:\n",
    "  - All values in the resulting matrices are non-negative\n",
    "  - Produces an additive, parts-based representation (unlike SVD)\n",
    "  - Often creates more interpretable components\n",
    "\n",
    "- **Advantages for Text Analysis**:\n",
    "  - Components often correspond to topics or themes\n",
    "  - Non-negative values align well with the intuition that topics add up to form documents\n",
    "  - Often works well for topic modeling and document clustering\n",
    "  - May capture different semantic relationships than SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "66ab8528-e6e3-4191-9425-fbae117c518b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00032308, 0.        , 0.        , 0.31244107,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=16)\n",
    "X_emb = nmf.fit_transform(X)\n",
    "X_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a73571ba-6f8a-4b24-bd97-18ca6eac92ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00098135, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17668529,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00079345,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = cv.transform([query])\n",
    "Q_emb = nmf.transform(Q)\n",
    "Q_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "77b4efea-db0d-4df5-8408-717ce953ae96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Please choose the closest one to your answer. Also do not post your answer in the course slack channel.',\n",
       " 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       " \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       " \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'No, it’s not possible. The form is closed after the due date. But don’t worry, homework is not mandatory for finishing the course.',\n",
       " 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       " 'If you have submitted two projects (and peer-reviewed at least 3 course-mates’ projects for each submission), you will get the certificate for the course. According to the course coordinator, Alexey Grigorev, only two projects are needed to get the course certificate.\\n(optional) David Odimegwu',\n",
       " 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       " 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cosine_similarity(X_emb, Q_emb).flatten()\n",
    "idx = np.argsort(-score)[:10]\n",
    "list(df.loc[idx].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "03778f26-e16a-4879-897e-7e15797fc364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.eval()  # Set the model to evaluation mode if not training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db76978",
   "metadata": {},
   "source": [
    "## 5. Advanced Embedding with BERT\n",
    "\n",
    "**BERT (Bidirectional Encoder Representations from Transformers)** represents a major advancement in text representation:\n",
    "\n",
    "- **Contextual Embeddings**: Unlike traditional methods, BERT generates word embeddings based on surrounding context\n",
    "  - The same word can have different embeddings in different contexts (e.g., \"bank\" in \"river bank\" vs. \"bank account\")\n",
    "\n",
    "- **Advantages over Traditional Methods**:\n",
    "  - Pre-trained on massive text corpora (Wikipedia, books)\n",
    "  - Captures deep semantic relationships and linguistic patterns\n",
    "  - Understands word meaning in context\n",
    "  - More effectively captures nuanced queries and document meanings\n",
    "\n",
    "- **Process**:\n",
    "  - Tokenize text into subwords\n",
    "  - Process through the transformer architecture\n",
    "  - Extract contextual embeddings (usually from the last hidden layer)\n",
    "  - Average or use special [CLS] token embeddings for sentence representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c7f95191-3b91-4137-ad6c-d6d22c03afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Yes, we will keep all the materials after the course finishes.\",\n",
    "    \"You can follow the course at your own pace after it finishes\"\n",
    "]\n",
    "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0c51bc5b-3908-42dc-88cc-c07b33a6ddc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2748,  1010,  2057,  2097,  2562,  2035,  1996,  4475,  2044,\n",
       "          1996,  2607, 12321,  1012,   102],\n",
       "        [  101,  2017,  2064,  3582,  1996,  2607,  2012,  2115,  2219,  6393,\n",
       "          2044,  2009, 12321,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "37cbdc75-0916-4360-b1a7-c8d03142398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    outputs = model(**encoded_input)\n",
    "    hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2e0c208b-d1a6-48d2-9080-130dd2f37f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 768])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "47fc911c-5ed7-4a97-86bd-b4bc2e311214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = hidden_states.mean(dim=1)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3dbe88f8-d39f-4b22-8f17-4d911c14e185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3599924 , -0.16072305,  0.35452363, ...,  0.04289253,\n",
       "         0.03482319, -0.03822242],\n",
       "       [ 0.17849939, -0.5000251 ,  0.25277585, ..., -0.11413134,\n",
       "        -0.33608466,  0.4109512 ]], shape=(2, 768), dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.numpy()\n",
    "\n",
    "# note that if use a GPU, first you need to move your tensors to CPU\n",
    "# sentence_embeddings_cpu = sentence_embeddings.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "032e6145-bf8d-4ccf-a592-0bf82c5822f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(seq, n):\n",
    "    result = []\n",
    "    for i in range(0, len(seq), n):\n",
    "        batch = seq[i:i+n]\n",
    "        result.append(batch)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c58b5",
   "metadata": {},
   "source": [
    "### Batch Processing for Efficient Embedding Generation\n",
    "\n",
    "Processing large collections of documents through BERT can be resource-intensive. We implement batch processing to:\n",
    "\n",
    "- **Manage Memory Usage**: Process smaller chunks of documents at a time\n",
    "- **Improve Performance**: Batch processing is more computationally efficient than one-by-one processing\n",
    "- **Track Progress**: Use tqdm to visualize completion progress\n",
    "- **Process Scale**: Enable handling of large document collections without running out of memory\n",
    "\n",
    "The approach:\n",
    "1. Split the document collection into smaller batches\n",
    "2. Process each batch through BERT\n",
    "3. Collect embeddings from each batch\n",
    "4. Combine all embeddings into a final output matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4d013583-f000-4c1c-88e4-b05dc5f91504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "57853a2c-2d45-460d-b929-6f6b564ed55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(texts, batch_size=8):\n",
    "    \"\"\"Generate BERT embeddings for a collection of texts efficiently.\n",
    "    \n",
    "    Args:\n",
    "        texts (list): List of text strings to encode\n",
    "        batch_size (int): Number of texts to process in each batch\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Matrix of embeddings, shape (num_texts, embedding_dim)\n",
    "    \"\"\"\n",
    "    # Split texts into batches for efficient processing\n",
    "    text_batches = make_batches(texts, batch_size)\n",
    "    \n",
    "    all_embeddings = []\n",
    "    \n",
    "    # Process each batch with a progress bar\n",
    "    for batch in tqdm(text_batches):\n",
    "        # Tokenize the batch of texts\n",
    "        # - padding=True ensures all sequences in the batch have the same length\n",
    "        # - truncation=True cuts texts that are too long\n",
    "        # - return_tensors='pt' returns PyTorch tensors\n",
    "        encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "        # Disable gradient calculation for inference (saves memory and is faster)\n",
    "        with torch.no_grad():\n",
    "            # Get BERT outputs for this batch\n",
    "            outputs = model(**encoded_input)\n",
    "            # Extract the hidden states from the last layer\n",
    "            hidden_states = outputs.last_hidden_state\n",
    "            \n",
    "            # Average token embeddings to get sentence embeddings\n",
    "            # (dimension 1 corresponds to tokens in each sequence)\n",
    "            batch_embeddings = hidden_states.mean(dim=1)\n",
    "            \n",
    "            # Convert PyTorch tensors to NumPy arrays\n",
    "            batch_embeddings_np = batch_embeddings.cpu().numpy()\n",
    "            all_embeddings.append(batch_embeddings_np)\n",
    "    \n",
    "    # Stack all batch embeddings into a single matrix\n",
    "    final_embeddings = np.vstack(all_embeddings)\n",
    "    return final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ba794951-7869-407c-a790-ae75419ca294",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "20357dc1-3fd1-4b0e-a476-88ce433e347a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing embeddings for section...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad50be134c9d419785c3df87d85edd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing embeddings for question...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e927b7d2f7c439bbec94712d62c2ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing embeddings for text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631c47e496ab415889941539b47d26d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fields = ['section', 'question', 'text']\n",
    "\n",
    "for f in fields:\n",
    "    print(f'computing embeddings for {f}...')\n",
    "    embeddings[f] = compute_embeddings(df[f].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0af125f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': array([[ 0.37748608, -0.16826633, -0.71794635, ...,  0.32759327,\n",
       "         -0.12342925,  0.18710026],\n",
       "        [ 0.37748608, -0.16826633, -0.71794635, ...,  0.32759327,\n",
       "         -0.12342925,  0.18710026],\n",
       "        [ 0.37748608, -0.16826633, -0.71794635, ...,  0.32759327,\n",
       "         -0.12342925,  0.18710026],\n",
       "        ...,\n",
       "        [-0.1783811 , -0.00579773, -0.19219266, ..., -0.09306458,\n",
       "          0.06128873, -0.07417933],\n",
       "        [-0.1783811 , -0.00579773, -0.19219266, ..., -0.09306458,\n",
       "          0.06128873, -0.07417933],\n",
       "        [-0.1783811 , -0.00579773, -0.19219266, ..., -0.09306458,\n",
       "          0.06128873, -0.07417933]], shape=(948, 768), dtype=float32),\n",
       " 'question': array([[-6.55925050e-02, -3.21504474e-01,  5.13027191e-01, ...,\n",
       "         -8.19995776e-02, -1.21371210e-01,  3.88520695e-02],\n",
       "        [ 2.28554845e-01,  4.20735665e-02,  2.02741608e-01, ...,\n",
       "         -8.88650045e-02,  4.93600965e-04,  8.19936686e-04],\n",
       "        [ 3.47465314e-02, -2.72454262e-01,  2.28157520e-01, ...,\n",
       "          5.96145838e-02, -1.28632829e-01,  1.58573195e-01],\n",
       "        ...,\n",
       "        [-1.18611656e-01, -1.78226024e-01,  2.52484947e-01, ...,\n",
       "         -1.09512553e-01,  1.72487468e-01,  2.15257391e-01],\n",
       "        [-1.62804857e-01, -5.89594305e-01, -1.57611281e-01, ...,\n",
       "         -8.96262676e-02, -3.30685884e-01,  8.41582194e-02],\n",
       "        [ 1.20504111e-01, -3.07611264e-02, -2.43602663e-01, ...,\n",
       "         -2.39552349e-01, -2.06390142e-01,  2.46759996e-01]],\n",
       "       shape=(948, 768), dtype=float32),\n",
       " 'text': array([[-0.00456301, -0.11667518,  0.6274717 , ..., -0.03659194,\n",
       "          0.10031687,  0.02927125],\n",
       "        [-0.1423361 , -0.1985391 ,  0.2845541 , ..., -0.01139048,\n",
       "         -0.15399769,  0.09535074],\n",
       "        [ 0.19672252, -0.0846131 ,  0.28200513, ...,  0.11395875,\n",
       "         -0.06448033, -0.01282622],\n",
       "        ...,\n",
       "        [-0.2821744 , -0.33324358,  0.29785   , ..., -0.35042733,\n",
       "          0.0326606 ,  0.09537265],\n",
       "        [-0.428071  , -0.39468744,  0.30941987, ..., -0.05943297,\n",
       "         -0.12965174,  0.07887056],\n",
       "        [-0.16892126, -0.25146264,  0.47843292, ..., -0.18535422,\n",
       "         -0.16108921,  0.27272934]], shape=(948, 768), dtype=float32)}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e30cf0c0-0522-411c-8e6f-3368aafd84e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "eb3fbe18-b993-4d03-890f-0a9f37ad11d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings.bin', 'wb') as f_out:\n",
    "    pickle.dump(embeddings, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "669c1d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings size: 8.33 MB\n"
     ]
    }
   ],
   "source": [
    "# size in MB of the embeddings\n",
    "import os\n",
    "embeddings_size = os.path.getsize('embeddings.bin') / (1024 * 1024)  # in MB\n",
    "print(f'Embeddings size: {embeddings_size:.2f} MB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7805f77",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've explored a progression of search techniques:\n",
    "\n",
    "1. We started with basic bag-of-words representations using CountVectorizer.\n",
    "2. We improved on this by using TF-IDF to account for term importance.\n",
    "3. We built a flexible search system with field boosting and filtering.\n",
    "4. We explored dimensionality reduction techniques (SVD and NMF) to handle the curse of dimensionality.\n",
    "5. Finally, we implemented state-of-the-art BERT embeddings to capture contextual meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c38dabc",
   "metadata": {},
   "source": [
    "## Comparison of Search Methods\n",
    "\n",
    "Here's a comparison of the different approaches we explored:\n",
    "\n",
    "| Method | Pros | Cons | Best for |\n",
    "|--------|------|------|----------|\n",
    "| **CountVectorizer** | Simple, fast, easy to understand | Ignores word importance, sensitive to common words | Quick prototyping, small collections |\n",
    "| **TF-IDF** | Accounts for term importance, works well in practice | Still bag-of-words (no word order), no semantic understanding | General purpose IR, medium-sized collections |\n",
    "| **SVD/LSA** | Reduces dimensions, finds latent relationships, handles synonyms | Loses interpretability, needs tuning | Handling synonym problem, reducing computation |\n",
    "| **NMF** | Topic-like components, more interpretable than SVD | Still no deep semantics, sensitive to initialization | Topic modeling applications |\n",
    "| **BERT** | Deep semantic understanding, context-aware, state-of-the-art | Computationally expensive, more complex | Understanding nuanced queries, semantic search |\n",
    "\n",
    "**Search Quality Progression**:\n",
    "1. Basic word counting (CountVectorizer) → Limited understanding\n",
    "2. Word importance weighting (TF-IDF) → Better results for distinctive terms\n",
    "3. Latent semantic analysis (SVD) → Some semantic connections\n",
    "4. Contextual embeddings (BERT) → Deep semantic understanding\n",
    "\n",
    "**Computational Cost Progression**:\n",
    "1. CountVectorizer → Very fast\n",
    "2. TF-IDF → Fast\n",
    "3. SVD/NMF → Moderate\n",
    "4. BERT → Most expensive\n",
    "\n",
    "When building a search system, the choice of method depends on your specific requirements for accuracy, speed, and available computational resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
