{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7205d6a9",
   "metadata": {},
   "source": [
    "# Homework Agents - LLM ZOOMCAMP - Rui Pinto\n",
    "\n",
    "In this homework, we will learn more about function calling,\n",
    "and we will also explore MCP - model-context protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6063cdd2",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "First, we'll define a function that we will use when building\n",
    "our agent. \n",
    "\n",
    "It will generate fake weather data:\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "known_weather_data = {\n",
    "    'berlin': 20.0\n",
    "}\n",
    "\n",
    "def get_weather(city: str) -> float:\n",
    "    city = city.strip().lower()\n",
    "\n",
    "    if city in known_weather_data:\n",
    "        return known_weather_data[city]\n",
    "\n",
    "    return round(random.uniform(-5, 35), 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bc51bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> float:\n",
    "    city = city.strip().lower()\n",
    "\n",
    "    if city in known_weather_data:\n",
    "        return known_weather_data[city]\n",
    "\n",
    "    return round(random.uniform(-5, 35), 1)\n",
    "\n",
    "\n",
    "known_weather_data = {\"berlin\": 20.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6960ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n",
      "26.6\n"
     ]
    }
   ],
   "source": [
    "print(get_weather(\"Berlin\"))  # Example usage, can be removed or modified as needed\n",
    "print(\n",
    "    get_weather(\"London\")\n",
    ")  # we do not have data for London, so it will return a random temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b055e38c",
   "metadata": {},
   "source": [
    "## Q1. Define function description\n",
    "\n",
    "We want to use it as a tool for our agent, so we need to \n",
    "describe it \n",
    "\n",
    "How should the description for this function look like? Fill in missing parts\n",
    "\n",
    "```python\n",
    "get_weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"<TODO1>\",\n",
    "    \"description\": \"<TODO2>\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"<TODO3>\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"<TODO4>\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [TODO5],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371995e7",
   "metadata": {},
   "source": [
    "### tool to get the weather for a city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b7bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO1 - get_weather\n",
    "# TODO2 - get the current weather for a specific city\n",
    "# TODO3 - city\n",
    "# TODO4 - the name of the city to get the weather for\n",
    "# TODO5 - \"city\"\n",
    "\n",
    "get_weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",  # Function to get the current temperature for a city\n",
    "    \"description\": \"Get current temperature for provided city in celsius.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the city to get the weather temperature for.\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8089ab6e",
   "metadata": {},
   "source": [
    "What did you put in `TODO3`?\n",
    "\n",
    "- location ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b208eb6",
   "metadata": {},
   "source": [
    "## Testing it (Optional)\n",
    "\n",
    "If you have OpenAI API Key (or alternative provider),\n",
    "let's test it.\n",
    "\n",
    "A question could be \"What's the weather like in Germany?\"\n",
    "\n",
    "Experiment with different system prompts to have better answers\n",
    "from the system.\n",
    "\n",
    "You can use [chat_assistant.py](https://github.com/alexeygrigorev/rag-agents-workshop/blob/main/chat_assistant.py)\n",
    "or implement everything yourself \n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d80bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16807de4",
   "metadata": {},
   "source": [
    "### OpenAI chat assistance calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4f72d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseFunctionToolCall(arguments='{\"location\":\"Germany\"}', call_id='call_nTRiCzTh0CQq9gMMMXq3r2CB', name='get_weather', type='function_call', id='fc_687e5a6cfc308199a2f6ef1e30fdfc3f0dc1c4cf1f397684', status='completed')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "input_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"What's the weather like in Germany?\",\n",
    "}\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\", input=[input_message], tools=[get_weather_tool]\n",
    ")\n",
    "\n",
    "print(response.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee3efae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Germany is 27.2 °C\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)\n",
    "\n",
    "# If your tool uses \"location\" as the key:\n",
    "city = args[\"location\"]\n",
    "weather = get_weather(city)\n",
    "print(f\"The weather in {city} is {weather} °C\")  # fake weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e883e8",
   "metadata": {},
   "source": [
    "## Q2. Adding another tool\n",
    "\n",
    "Let's add another tool - a function that can add weather data\n",
    "to our database:\n",
    "\n",
    "```python\n",
    "def set_weather(city: str, temp: float) -> None:\n",
    "    city = city.strip().lower()\n",
    "    known_weather_data[city] = temp\n",
    "    return 'OK'\n",
    "```\n",
    "\n",
    "Now let's write a description for it.\n",
    "\n",
    "What did you write?\n",
    "\n",
    "Optionally, you can test it after adding this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb26d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_weather(location: str, temp: float) -> None:\n",
    "    location = location.strip().lower()\n",
    "    known_weather_data[location] = temp\n",
    "    return \"OK\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d948ace1",
   "metadata": {},
   "source": [
    "### tool to set the weather for a city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d8df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"set_weather\",\n",
    "    \"description\": \"Set the current temperature for a specific location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the location to set the weather for.\",\n",
    "            },\n",
    "            \"temp\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The temperature to set for the location (in Celsius).\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"location\", \"temp\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f210758a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseFunctionToolCall(arguments='{\"location\":\"Paris\",\"temp\":25}', call_id='call_teosXggyAfi4B9HAUYUfxjRE', name='set_weather', type='function_call', id='fc_687e5a6e4a74819ab226f7673cac462008bb74cfdf668614', status='completed')]\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "input_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Set the weather for Paris to 25 °C?\",\n",
    "}\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\", input=[input_message], tools=[set_weather_tool]\n",
    ")\n",
    "\n",
    "print(response.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75e5b1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set the weather in Paris was successful: OK to 25 °C\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)\n",
    "\n",
    "# If your tool uses \"location\" as the key:\n",
    "location = args[\"location\"]\n",
    "confirmation = set_weather(location, args[\"temp\"])\n",
    "print(\n",
    "    f\"Set the weather in {location} was successful: {confirmation} to {args['temp']} °C\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d88286",
   "metadata": {},
   "source": [
    "### Multiple tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "759ed7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding more tools\n",
    "tools = [get_weather_tool, set_weather_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e1d60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_call(entry):\n",
    "    if entry.name == \"get_weather\":\n",
    "        args = json.loads(entry.arguments)\n",
    "        return get_weather(args[\"location\"])\n",
    "    elif entry.name == \"set_weather\":\n",
    "        args = json.loads(entry.arguments)\n",
    "        return set_weather(args[\"location\"], args[\"temp\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown tool call: {entry.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6ae0858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function call requested: get_weather with arguments {\"location\":\"Berlin\"}\n",
      "Function call requested: get_weather with arguments {\"location\":\"Berlin\"}\n",
      "Function call requested: get_weather with arguments {\"location\":\"Berlin\"}\n",
      "Assistant: [ResponseOutputText(annotations=[], text='The weather in Berlin is currently 25 °C.', type='output_text', logprobs=[])]\n",
      "Function call requested: get_weather with arguments {\"location\":\"Paris\"}\n",
      "Function call requested: get_weather with arguments {\"location\":\"Paris\"}\n",
      "Function call requested: get_weather with arguments {\"location\":\"Paris\"}\n",
      "Assistant: [ResponseOutputText(annotations=[], text='The weather in Paris is currently 25 °C.', type='output_text', logprobs=[])]\n",
      "Function call requested: set_weather with arguments {\"location\":\"Paris\",\"temp\":45}\n",
      "Function call requested: set_weather with arguments {\"location\":\"Paris\",\"temp\":45}\n",
      "Function call requested: set_weather with arguments {\"location\":\"Paris\",\"temp\":45}\n",
      "Function call requested: set_weather with arguments {\"location\":\"Paris\",\"temp\":45}\n",
      "Function call requested: set_weather with arguments {\"location\":\"Paris\",\"temp\":45}\n",
      "Assistant: [ResponseOutputText(annotations=[], text=\"I've set the weather in Paris to 45 °C.\", type='output_text', logprobs=[])]\n",
      "Function call requested: get_weather with arguments {\"location\":\"Paris\"}\n",
      "Assistant: [ResponseOutputText(annotations=[], text='The weather in Paris is currently 45 °C.', type='output_text', logprobs=[])]\n",
      "Function call requested: get_weather with arguments {\"location\":\"Paris\"}\n",
      "Function call requested: get_weather with arguments {\"location\":\"Paris\"}\n",
      "Assistant: [ResponseOutputText(annotations=[], text='The weather in Paris is currently 45 °C.', type='output_text', logprobs=[])]\n"
     ]
    }
   ],
   "source": [
    "# Store the chat history\n",
    "chat_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant. After each function call, use the result to answer the user's question directly.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "max_steps = 5\n",
    "steps = 0\n",
    "\n",
    "# Main agent loop\n",
    "while steps < max_steps:\n",
    "    # Get user input\n",
    "    question = input(\"Ask a question (or type 'stop' to exit): \")\n",
    "    if question.lower() == \"stop\":\n",
    "        break\n",
    "\n",
    "    # Add user message to chat history\n",
    "    chat_messages.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "    # Keep looping until we get a final assistant message\n",
    "    while True:\n",
    "        # Send chat history and tools to OpenAI\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o-mini\", input=chat_messages, tools=tools\n",
    "        )\n",
    "\n",
    "        has_function_call = False\n",
    "\n",
    "        # Process each entry in the response\n",
    "        for entry in response.output:\n",
    "            if entry.type == \"function_call\":\n",
    "                print(\n",
    "                    f\"Function call requested: {entry.name} with arguments {entry.arguments}\"\n",
    "                )\n",
    "                result = do_call(entry)\n",
    "                args = json.loads(entry.arguments)\n",
    "                if entry.name == \"get_weather\":\n",
    "                    chat_messages.append(\n",
    "                        {\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"content\": f\"The weather in {args['location'].title()} is {result} °C.\",\n",
    "                        }\n",
    "                    )\n",
    "                elif entry.name == \"set_weather\":\n",
    "                    chat_messages.append(\n",
    "                        {\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"content\": f\"Set the weather in {args['location'].title()} to {args['temp']} °C: {result}\",\n",
    "                        }\n",
    "                    )\n",
    "                has_function_call = True\n",
    "                break\n",
    "            elif entry.type == \"message\":\n",
    "                print(\"Assistant:\", entry.content)\n",
    "                chat_messages.append({\"role\": \"assistant\", \"content\": entry.content})\n",
    "                has_function_call = False\n",
    "                break\n",
    "\n",
    "        if has_function_call:\n",
    "            continue  # Make a new API call with the function output\n",
    "        else:\n",
    "            break  # End the loop after printing the assistant's message\n",
    "    steps += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c635e",
   "metadata": {},
   "source": [
    "## MCP\n",
    "\n",
    "MCP stands for Model-Context Protocol. It allows LLMs communicate\n",
    "with different tools (like Qdrant). It's function calling, but \n",
    "one step further:\n",
    "\n",
    "* A tool can export a list of functions it has\n",
    "* When we include the tool to our Agent, we just need to include the link to the MCP server\n",
    "\n",
    "## Q3. Install FastMCP\n",
    "\n",
    "Let's install a library for MCP - [FastMCP](https://github.com/jlowin/fastmcp):\n",
    "\n",
    "```bash\n",
    "pip install fastmcp\n",
    "```\n",
    "\n",
    "What's the version of FastMCP you installed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3f12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.6\n"
     ]
    }
   ],
   "source": [
    "#!uv add fastmcp\n",
    "\n",
    "import fastmcp\n",
    "\n",
    "# version of fastmcp\n",
    "print(fastmcp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748343ec",
   "metadata": {},
   "source": [
    "## Q4. Simple MCP Server \n",
    "\n",
    "A simple MCP server from the documentation looks like that:\n",
    "\n",
    "```python\n",
    "# weather_server.py\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Demo 🚀\")\n",
    "\n",
    "@mcp.tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()\n",
    "```\n",
    "\n",
    "In our case, we need to write docstrings for our functions.\n",
    "\n",
    "Let's ask ChatGPT for help:\n",
    "\n",
    "```python\n",
    "def get_weather(city: str) -> float:\n",
    "    \"\"\"\n",
    "    Retrieves the temperature for a specified city.\n",
    "\n",
    "    Parameters:\n",
    "        city (str): The name of the city for which to retrieve weather data.\n",
    "\n",
    "    Returns:\n",
    "        float: The temperature associated with the city.\n",
    "    \"\"\"\n",
    "    city = city.strip().lower()\n",
    "\n",
    "    if city in known_weather_data:\n",
    "        return known_weather_data[city]\n",
    "\n",
    "    return round(random.uniform(-5, 35), 1)\n",
    "\n",
    "\n",
    "def set_weather(city: str, temp: float) -> None:\n",
    "    \"\"\"\n",
    "    Sets the temperature for a specified city.\n",
    "\n",
    "    Parameters:\n",
    "        city (str): The name of the city for which to set the weather data.\n",
    "        temp (float): The temperature to associate with the city.\n",
    "\n",
    "    Returns:\n",
    "        str: A confirmation string 'OK' indicating successful update.\n",
    "    \"\"\"\n",
    "    city = city.strip().lower()\n",
    "    known_weather_data[city] = temp\n",
    "    return 'OK'\n",
    "```\n",
    "\n",
    "Let's change the example for our case and run it\n",
    "\n",
    "What do you see in the output?\n",
    "\n",
    "Look for a string that matches this template:\n",
    "\n",
    "```\n",
    "Starting MCP server 'Demo 🚀' with transport '<TODO>'\n",
    "```\n",
    "\n",
    "What do you have instead of `<TODO>`? - stdio ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9e733e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start mcp server in weather.py\n",
    "#!uv run weather.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79353bf",
   "metadata": {},
   "source": [
    "## Q5. Protocol\n",
    "\n",
    "There are different ways to communicate with an MCP server.\n",
    "Ours is currently running using standart input/output, which\n",
    "means that the client write something to stdin and read the\n",
    "answer using stdout.\n",
    "\n",
    "Our weather server is currently running.\n",
    "\n",
    "This is how we start communitcating with it:\n",
    "\n",
    "- First, we send an initialization request -- this way, we register our client with the server:\n",
    "    ```json\n",
    "    {\"jsonrpc\": \"2.0\", \"id\": 1, \"method\": \"initialize\", \"params\": {\"protocolVersion\": \"2024-11-05\", \"capabilities\": {\"roots\": {\"listChanged\": true}, \"sampling\": {}}, \"clientInfo\": {\"name\": \"test-client\", \"version\": \"1.0.0\"}}}\n",
    "    ```\n",
    "    We should get back something like that, which is an aknowledgement of the request:\n",
    "    ```json\n",
    "    {\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{\"protocolVersion\":\"2024-11-05\",\"capabilities\":{\"experimental\":{},\"prompts\":{\"listChanged\":false},\"resources\":{\"subscribe\":false,\"listChanged\":false},\"tools\":{\"listChanged\":true}},\"serverInfo\":{\"name\":\"Demo 🚀\",\"version\":\"1.9.4\"}}}\n",
    "    ```\n",
    "-  Next, we reply back, confirming the initialization:\n",
    "    ```json\n",
    "    {\"jsonrpc\": \"2.0\", \"method\": \"notifications/initialized\"}\n",
    "    ```\n",
    "    We don't expect to get anything in response\n",
    "- Now we can ask for a list of available methods:\n",
    "    ```json\n",
    "    {\"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"tools/list\"}\n",
    "    ```\n",
    "- Let's ask the temperature in Berlin:\n",
    "    ```json\n",
    "    {\"jsonrpc\": \"2.0\", \"id\": 3, \"method\": \"tools/call\", \"params\": {\"name\": \"<TODO>\", \"arguments\": {<TODO>}}}\n",
    "    ```\n",
    "- What did you get in response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da962bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start fastmcp server\n",
    "# uv run weather_server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b3a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{\"protocolVersion\":\"2024-11-05\",\"capabilities\":{\"experimental\":{},\"prompts\":{\"listChanged\":false},\"resources\":{\"subscribe\":false,\"listChanged\":false},\"tools\":{\"listChanged\":true}},\"serverInfo\":{\"name\":\"Weather 🚀\",\"version\":\"1.12.0\"}}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{\"jsonrpc\":\"2.0\",\"id\":2,\"result\":{\"tools\":[{\"name\":\"get_weather\",\"description\":\"Retrieves the temperature for a specified city.\\n\\nParameters:\\n    city (str): The name of the city for which to retrieve weather data.\\n\\nReturns:\\n    float: The temperature associated with the city.\",\"inputSchema\":{\"properties\":{\"city\":{\"title\":\"City\",\"type\":\"string\"}},\"required\":[\"city\"],\"type\":\"object\"},\"outputSchema\":{\"properties\":{\"result\":{\"title\":\"Result\",\"type\":\"number\"}},\"required\":[\"result\"],\"title\":\"_WrappedResult\",\"type\":\"object\",\"x-fastmcp-wrap-result\":true}},{\"name\":\"set_weather\",\"description\":\"Sets the temperature for a specified city.\\n\\nParameters:\\n    city (str): The name of the city for which to set the weather data.\\n    temp (float): The temperature to associate with the city.\\n\\nReturns:\\n    str: A confirmation string 'OK' indicating successful update.\",\"inputSchema\":{\"properties\":{\"city\":{\"title\":\"City\",\"type\":\"string\"},\"temp\":{\"title\":\"Temp\",\"type\":\"number\"}},\"required\":[\"city\",\"temp\"],\"type\":\"object\"},\"outputSchema\":{\"properties\":{\"result\":{\"title\":\"Result\",\"type\":\"string\"}},\"required\":[\"result\"],\"title\":\"_WrappedResult\",\"type\":\"object\",\"x-fastmcp-wrap-result\":true}}]}}\n",
      "\n",
      "\n",
      "{\"jsonrpc\":\"2.0\",\"id\":3,\"result\":{\"content\":[{\"type\":\"text\",\"text\":\"20.0\"}],\"structuredContent\":{\"result\":20.0},\"isError\":false}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "proc = subprocess.Popen(\n",
    "    [\"python\", \"weather_server.py\"],\n",
    "    stdin=subprocess.PIPE,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "\n",
    "def send_to_mcp(proc, request_json, expect_response=True):\n",
    "    proc.stdin.write(request_json + \"\\n\")\n",
    "    proc.stdin.flush()\n",
    "    if expect_response:\n",
    "        return proc.stdout.readline().strip()\n",
    "\n",
    "\n",
    "# 1. Initialize\n",
    "init_request = '{\"jsonrpc\": \"2.0\", \"id\": 1, \"method\": \"initialize\", \"params\": {\"protocolVersion\": \"2024-11-05\", \"capabilities\": {\"roots\": {\"listChanged\": true}, \"sampling\": {}}, \"clientInfo\": {\"name\": \"test-client\", \"version\": \"1.0.0\"}}}'\n",
    "print(send_to_mcp(proc, init_request, expect_response=True))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Confirm initialization (no response expected)\n",
    "confirm_init = '{\"jsonrpc\": \"2.0\", \"method\": \"notifications/initialized\"}'\n",
    "send_to_mcp(proc, confirm_init, expect_response=False)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3. List tools\n",
    "list_tools = '{\"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"tools/list\", \"params\": {}}'\n",
    "print(send_to_mcp(proc, list_tools, expect_response=True))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4. Call get_weather for Berlin\n",
    "import json  # Add this at the top if not present\n",
    "\n",
    "call_get_weather = json.dumps(\n",
    "    {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 3,\n",
    "        \"method\": \"tools/call\",\n",
    "        \"params\": {\"name\": \"get_weather\", \"arguments\": {\"city\": \"Berlin\"}},\n",
    "    }\n",
    ")\n",
    "print(send_to_mcp(proc, call_get_weather, expect_response=True))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "proc.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6e2e6",
   "metadata": {},
   "source": [
    "## Q6. Client\n",
    "\n",
    "We typically don't interact with the server by copy-pasting \n",
    "commands in the terminal.\n",
    "\n",
    "In practice, we use an MCP Client. Let's implement it. \n",
    "\n",
    "FastMCP also supports MCP clients:\n",
    "\n",
    "```python\n",
    "from fastmcp import Client\n",
    "\n",
    "async def main():\n",
    "    async with Client(<TODO>) as mcp_client:\n",
    "        # TODO\n",
    "```\n",
    "\n",
    "Use the client to get the list of available tools\n",
    "of our script. How does the result look like?\n",
    "\n",
    "If you're running this code in Jupyter, you need to pass\n",
    "an instance of MCP server to the `Client`:\n",
    "\n",
    "```python\n",
    "import weather_server\n",
    "\n",
    "async def main():\n",
    "    async with Client(weather_server.mcp) as mcp_client:\n",
    "        # ....\n",
    "```\n",
    "\n",
    "If you run it in a script, you will need to use asyncio:\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    async with Client(\"weather_server.py\") as mcp_client:\n",
    "        # ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test = asyncio.run(main())\n",
    "```\n",
    "\n",
    "Copy the output with the available tools when\n",
    "filling in the homework form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f1c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool(name='get_weather', title=None, description='Retrieves the temperature for a specified city.\\n\\nParameters:\\n    city (str): The name of the city for which to retrieve weather data.\\n\\nReturns:\\n    float: The temperature associated with the city.', inputSchema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'type': 'object'}, outputSchema={'properties': {'result': {'title': 'Result', 'type': 'number'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True}, annotations=None, meta=None), Tool(name='set_weather', title=None, description=\"Sets the temperature for a specified city.\\n\\nParameters:\\n    city (str): The name of the city for which to set the weather data.\\n    temp (float): The temperature to associate with the city.\\n\\nReturns:\\n    str: A confirmation string 'OK' indicating successful update.\", inputSchema={'properties': {'city': {'title': 'City', 'type': 'string'}, 'temp': {'title': 'Temp', 'type': 'number'}}, 'required': ['city', 'temp'], 'type': 'object'}, outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True}, annotations=None, meta=None)]\n"
     ]
    }
   ],
   "source": [
    "import weather_server\n",
    "from fastmcp import Client\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def main():\n",
    "    async with Client(weather_server.mcp) as mcp_client:\n",
    "        tools = await mcp_client.list_tools()\n",
    "        print(tools)\n",
    "\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-zoomcamp-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
